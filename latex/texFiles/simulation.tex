Initially, we considered an elementary hidden markov model on the golden eagle data. The data contains $45.914$ observations of spatiotemporal information for $58$ total tracks divided into $599$ segments. Each observation has a temporal resolution of one minute.\cite{eagleData} We used the variables: \texttt{Segment\_ID}, \texttt{Longitude}, \texttt{Latitude}, \texttt{Altitude}, \texttt{horizontal\_steps}. Although, it had been tidied already, we still did some minor data wrangling; we calculated the difference in altitude between consecutive observations within segments. Obviously, by doing so we had to discard the first observation for each segment. This left us with $45.315$ observations. Apart from this we found no issues with the data: We present summary statistics and density plots of the variables above in appendix \ref{summarStatistics} and we noted no unrealistic- og missing values.\\ With inspiration from \cite{Pirotta2018} we use the Stamen map API in \cite{ggmap} to depict all the segments with coordinates in the north-eastern United States; the vast-majority of the observations.
\begin{figure}[h]
    \begin{center}
        \includegraphics[scale = .095]{figures/allBirdTracks.jpeg}
        \caption{The segments of the $44.730$ observations in the north-eastern US.}
    \end{center}
\end{figure}
\subsection{Fitting an HMM to the Golden eagle segments}\label{hmmGoldenEagle}
Having dealt with the exploratory analysis of the eagle data, we commenced the modelling part. We used a weibull distribution for the horizontal steps and a normal distribution for the vertical steps. An our assumption was that the eagles had three behavioural states. In sum, $X_t \sim \mathcal{W}(k_i, \lambda_i), \; Y_t \sim \mathcal{N}(\mu_i, \sigma_i^2), \; i = 1,2,3$. For the fitting we of course  had to pick some starting values for $(k_i, \lambda_i, \mu_i, \sigma_i^2)$. As with any numerical maximization problem, this was primarily based on heuristics. We tried a few different strategies, for simplicity however, we only consider initialization based on the maximum likelihood estimates here. For our observed states these are given by\cite{Cohen1965}
\begin{align}
    \hat{\mu} &= \frac{1}{N}\sum_{i = 1}^N x_i, \quad \hat{\sigma}^2 = \frac{1}{N}\sum_{i = 1}^N \left(x_i-\hat{\mu}\right)^2\\
    \frac{1}{N}\sum_{i = 1}^N \log(y_i)&= \frac{\sum_{i = 1}^N y_i^k\log(y_i)}{\sum_{i = 1}^N y_i^k} - \frac{1}{k} \label{kMLE} \\  \hat{\lambda} &= \left(\frac{1}{N} \sum_{i = 1}^N y_i^{\hat{k}}\right)^{\frac{1}{\hat{k}}}
\end{align}
Where we used numerical methods \cite{RLang} to find the MLE for $k$ in (\ref{kMLE}). That is our strategy was simply to use the common estimates for each parameters as initialization in all of the $3$ states. We also tried a bit more sophisticated procedure: Seperating the data first by means of k-means clustering \cite{RLang} and then using the above heuristic on each cluster.
\subsection{Simulating hidden markov models}\label{simHMM}
After completing the initial modelling, we explored methods to enhance the model by relaxing the assumption of conditional independence. To achieve this, we established a framework that facilitated the sampling of hidden Markov models. By fitting the true model to this simulated data under different scenarios, we gained insights into the consequences of violating the conditional independece assumption for quality of the fit - and how relaxing the model remedied the issue.\\
As it was a pivotal part of the simulation and it could not be vectorized, we implemented a fast markov chain sampler in C++ \cite{Rcpp}. This simulates the underlying state sequence up to 100 times faster than a direct R implementation (see figure \ref{markovChainRvRcpp} in appendix \ref{benchmarkSection}). Then we drew from a weibull- and normal distribution, where the parameters depended on the state as in \ref{hmmGoldenEagle}. This we did both where the observed state at time $t$ was conditionally independent given the state and where there was various degress of correlation. Sampling independently was a trivial task. On the other hand, we wanted to be able to mimick the eagle data later on with varying degrees of correlation, wherefore we had to devise a way of sampling correlated weibull-normal samples. 
\subsection{Sampling correlated variables in the observed state sequence}\label{correlatedVariables}
In this part, we deviated from the regular hidden markov model by allowing correlation in the observed chain. We did this completely analagously to the sampling described in section \ref{simHMM}. The only thing we needed was a way to sample correlated variables from arbitrary distributions.
\subsubsection{Sampling correlated variables}
Motivated by us wanting to keep the same marginal distributions as in the initial fitting, we independently developed a method of simulating correlated variables with any parameterized distribution, the procedure is similar to \cite{thomasWard}. Our primary focus was of course the weibull and gaussian distributions; the following sampling procedure does however extend to any imaginable parameterized set of distributions.\\ Firstly, sample $X = (X_1, X_2)$ from a bivariate gaussian distribution with mean vector, $\xi = \mathbf{0}$ and covariance matrix 
\begin{align}\Sigma = \begin{pmatrix}
    1 & \rho \\
    \rho & 1
\end{pmatrix}
\end{align}
By this construction $\rho$ is the correlation between $X_1$ and $X_2$. Now, transform the samples in the following way: First transform $X$ into bivariate uniform samples $Y = (\Phi(X_1),\Phi(X_2))$. Then let $Z = (G_1(Y_1), G_2(Y))$, where $G_1, G_2$ are quantile functions of parameterized distributions and not necessarily the same. By applying the quantile transformation theorem twice in a back and forth manner, we see that $Z_1$ and $Z_2$ has distributions corresponding to $G_1, G_2$ respectively. Obviously, the correlation is no longer $\rho$ since the maps $\Phi$ and $G_1, G_2$ are non-linear. Though, obtaining an analytic expression for the correlation of $Z$ is beyond the scope of this project. Therefore, we rely on experimentation to determine the precise correlation. However, our sampling approach consistently results in a correlation we can somewhat control; the value of it is often in the vicinity of $\rho$. Refer to table \ref{correlationTable} in appendix \ref{simWeibullGaussian} for an example of this phenomenon. Also note on figure \ref{correlationDensities1}, that we indeed have the desired flexibility to choose our own marginal distributions. Furthermore, this method can seamlessly be combined with \ref{simHMM}. By the parameterized nature of the distribution the observed sequence can just as before directly depend on the state sequence by letting the parameters depend on the value of it. To implement this model the only thing we now needed was finding the general expression for the density of $Z$. In our study we have settle with deriving the density function of the weibull-normal distribution. The detailed derivation can be found in appendix \ref{weibullGaussianAppendix}. An extenstion of that proof would yield the general density for $Z$. Once the density is found it is quite easy (and necessary) to optimize the computation of the it with C++\cite{Rcpp}.
\subsubsection{Imitating the golden eagle data with varying correlation}\label{eagleImitation}
Lastly, we explored the impact of altering the correlation between the observed variables in the eagle data on the quality of the fit. Our sampling approach was ideal for this; it allowed us to give the observations the desired correlation while letting each of the variables maintain their marginal resemblance to the original data. More specifically, the main idea was replicating the eagles' hidden states according to the state transition probability matrix and initial state vector of the basic HMM fit and then use the estimated parameters of the observed states along with the sampling procedure desribed in section \ref{correlatedVariables} for various values of $\rho$. That is, the transformations of our bivariate normal samples depended on the underlying state sequence. One thing that was slightly different to our previous sampling was that we had to take the different nature of chains that should replicate segments of observations into account. That is we had to restart the chain each time a segment ended and then use the initial state probabilities to simulate the first state in the next segment.