\section{Source code}\label{sourceCode}
The source code for this project is in the Github repository by the name of \href{https://github.com/Gantzhorn/Project-in-Statistics}{Project-In-Statistics}. The owner of the repository is \textit{Gantzhorner}. Do note that it it licensed under the GNU General Public License v3.0. Select source code is shown in appendix \ref{sourceCodeImplementation}.
\section{Summary statistics and marginal distributions for the golden eagle data}
\label{summarStatistics}
\begin{table}[ht]
    \centering
    \begin{tabular}{lllll}
      \hline
    \textbf{Statistic} &   \textbf{Longitude} &    \textbf{Latitude} & \textbf{horizontal\_steps} & \textbf{vertical\_steps} \\ 
      \hline
    Min. &   -80.47   & 38.91   &    0.226   & -2285.2101   \\ 
      1st Quantile & -78.32   & 40.22   & 233.566   & -55.4587   \\ 
      Median & -77.56   & 41.06   &  519.348   &    -0.3183   \\ 
      Mean   & -77.31   & 41.00   & 566.544   & -0.9842   \\ 
      3rd Quantile & -76.47   & 41.64   & 855.376   & 51.3704   \\ 
      Max.   & -69.43   & 48.52   & 3807.510   & 996.1946   \\ 
       \hline
    \end{tabular}
    \caption{Short statistics from R's summary command for the most important variables in the eagle data}
    \label{tabularEagles}
\end{table}
\begin{figure}[h!]
    \centering
        \includegraphics[scale = .175]{figures/horizontalAndVerticalDensities.jpeg}
        \caption{Marginal densities for step lengths in both dimensions and their joint distribution\\ Note that the axes depicting the horizontal steps are shown on a logarithmic scale}
        \label{densityEagles}
\end{figure}
\newpage
\section{Correlated data auxiliary results}\label{simWeibullGaussian}
\subsection{Simulation study}\label{simstudyappendix}
For varying levels of correlation $\rho$ in the bivariate normal we simulate $2.500$ gaussian weibull variables with $k=2, \; \lambda = 5, \; \mu = 4, \; \sigma = 3$. For each correlation we use MLE to estimate the parameters. Additionaly, we find the Monte Carlo estimate for the correlation of the weibull-gaussian data, $\hat{\rho}_{prev}$
\begin{table}[ht]
    \centering
    \begin{tabular}{rrrrrr}
          \hline
          $\rho$ & $\hat{k}$ & $\hat{\lambda}$ & $\hat{\mu}$ & $\hat{\sigma}$ & $\hat{\rho}_{prev}$\\ 
          \hline
        -0.9 & 2.016813 & 4.999784 & 4.0 & 3.0 & -0.886736 \\ 
          -0.45 & 1.990909 & 5.000908 & 4.0& 3.0 & -0.443799 \\ 
          -0.1 & 1.993609 & 4.999045 & 4.0 & 3.0 & -0.100261 \\ 
          0.9 & 2.000166 & 5.001516 & 4.0 & 3.0 & 0.889852 \\ 
          0.45 & 2.000223 & 5.001611 & 4.0 & 3.0 & 0.440810 \\ 
          0.1 & 2.015213 & 5.002888 & 4.0 & 3.0 & 0.101309 \\ 
           \hline
        \end{tabular}
    \caption{Estimated parameters in the simulated data}
    \label{correlationTable}
\end{table}\\
We plot the joint - and marginal distributions for the data in table \ref{correlationTable}.
\begin{figure}[h!]
        \begin{center}
        \includegraphics[scale = .225]{figures/correlatedWeibullNormalSim.jpeg}
        \caption{Joint - and marginal distributions for the data in table \ref{correlationTable} with negative correlation in the first row and positive in the second row}
    \end{center}
    \label{correlationDensities1}
\end{figure}

\subsection{Imitated eagle data}
This section shows analagously to appendix \ref{simstudyappendix} the results of altering the correlation in the eagle data. This was done like explained in section \ref{eagleImitation}. Using the same values as in appendix \ref{simstudyappendix}. The sampling resulted in the monte-carlo estimates, $\hat{\rho}$ for the correlation of $\rho$.
\begin{table}[ht]
    \centering
    \begin{tabular}{rrr}
      \hline
     & $\rho$ & $\hat{\rho}$ \\ 
      \hline
    1 & -0.900000 & -0.706768 \\ 
      2 & -0.450000 & -0.458117 \\ 
      3 & -0.100000 & -0.276326 \\ 
      4 & 0.900000 & 0.269978 \\ 
      5 & 0.450000 & 0.024760 \\ 
      6 & 0.100000 & -0.167893 \\ 
       \hline
    \end{tabular}
    \caption{Estimated correlation in the altered eagle data based on $\rho$.}
    \label{correlatedEagleTable}
    \end{table}

    \begin{figure}[h!]
        \begin{center}
        \includegraphics[scale = .15]{figures/correlatedEaglesSim.jpeg}
        \caption{Joint - and marginal distributions for the data in table \ref{correlatedEagleTable} with negative correlation in the first row and positive in the second row}
    \end{center}
    \label{correlationEagleDensities}
\end{figure}
\newpage
\section{Findings auxilliary results}\label{auxiliaryResultsModelling}
This part shows different additional plots and graphs found in the modelling and simulations.
\subsection{Fitting an HMM to the Golden eagle segments}\label{goldenEagleSegments}
\begin{table}[ht]
    \centering
    \begin{tabular}{lcccc}
      \hline
      & $\mathbb{E}\left[X\right]$ & $\sigma_X$ & $\mathbb{E}\left[Y\right]$ & $\sigma_Y$ \\ 
      \hline
      \textbf{State 1} & 931.65 & 303.71 & -40.00 & 104.80 \\ 
      \textbf{State 2} & 373.36 & 221.89 & 30.11 & 78.72 \\ 
      \textbf{State 3} & 19.47 & 19.02 & -1.39 & 28.11 \\ 
       \hline
    \end{tabular}
    \caption{Mean and standard deviation of the final fit for each dimension and state}
    \label{initialFitMeans}
\end{table}
\begin{figure}[h]
    \begin{center}
        \includegraphics[scale = .14]{figures/AltitudeFourBirds.jpeg}
    \end{center}
    \caption{Altitude as a function of time since start of segment for four selected segments.}
    \label{fourSegments}
\end{figure}
\newpage
\begin{figure}[h]
    \begin{center}
        \includegraphics[scale = .1]{figures/horizontalStepsCombinedDistributionInitialFitZoom.jpeg}
    \end{center}
    \caption{Zoom of marginal distribution of the horizontal steps}
    \label{zoomHorizontal}
\end{figure}
\subsection{Simulating from hidden markov models without conditional independence}
\begin{figure}[h]
  \centering
  \includegraphics[scale = .12]{figures/logbiasPlotIndependent.jpeg}
  \caption{The logarithm of the absolute bias after state and parameter of the conditionally independent simulated data}
  \label{logbiasPlotIndependent}
\end{figure}\newpage
\subsection{Imitating the golden eagle data with varying correlation}
\begin{figure}[h]
  \centering
  \begin{minipage}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth]{figures/pseudoResidualsWeibullNormal1.jpeg}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth]{figures/pseudoResidualsWeibullNormal2.jpeg}
  \end{minipage}
  \caption{QQ-plots for the pseudoresiudals of both variables in the model with correlation}
  \label{combinedQQPlotsCorrelation}
\end{figure}
\subsection{Fitting the eagle data with the weibull-normal density}
\begin{table}[ht]
  \centering
  \begin{tabular}{lcccc}
    \hline
    & $\mathbb{E}\left[X\right]$ & $\sigma_X$ & $\mathbb{E}\left[Y\right]$ & $\sigma_Y$ \\ 
    \hline
    \textbf{State 1} & 917.45 & 434.71 & -27.27 & 117.91 \\ 
    \textbf{State 2} & 394.76 & 292.61 & 1.95 & 88.24 \\ 
    \textbf{State 3} & 28.15 & 33.50 & -1.55 & 30.82 \\ 
     \hline
  \end{tabular}
  \caption{Mean and standard deviation of the initial fit for each dimension and state}
  \label{finalFitMeans}
\end{table}
\begin{table}[h]
  \centering
  \begin{tabular}{ccc}
      \hline
      \textbf{Original Decoded State} & \textbf{New Decoded State} & \textbf{Count} \\
      \hline
      1 & 1 & 15713 \\
      1 & 2 & 2260 \\
      2 & 1 & 2571 \\
      2 & 2 & 20484 \\
      2 & 3 & 168 \\
      3 & 2 & 101 \\
      3 & 3 & 4018 \\
      \hline
  \end{tabular}
  \caption{Change in decoding from the Viterbi algorithm, between our initial and final fit.}
  \label{changeEstimFit}
\end{table}
\newpage
\section{Finding the density of the Weibull-Gaussian distribution}\label{weibullGaussianAppendix}
To find the density of the Weibull-Gaussian distribution, we let $(X_1, X_2)$ be bivariate gaussian with mean vector, $\xi = \mathbf{0}$ and covariance matrix $\Sigma = \begin{pmatrix}
    1 & \rho \\
    \rho & 1
\end{pmatrix}$. Now, we apply the methodology described in section \ref{correlatedVariables} in the following way. Let $Y$ be the transformed variable. Since we want $Y_1$ just to be a non-standard gaussian we can skip the quantile tranformation theorem on this entry. Therefore define the map $h_1: \mathbb{R}^2 \mapsto \mathbb{R}$ by $h_1(x_1, x_2) = x_1\sigma + \mu$ and $h_2:\mathbb{R}^2 \mapsto \mathbb{R}$ as $ h_2(x_1, x_2) = \lambda\left(-\log\left(1-\Phi(x_2)\right)\right)^{\frac{1}{k}}$. Defining 
\begin{align}
    Y = \begin{pmatrix}
        h_1(x_1, x_2)\\
        h_2(x_1, x_2)
    \end{pmatrix}    
\end{align}
we have be the quantile tranformation theorem that
$Y_1 \sim \mathcal{N}(\mu, \sigma^2)$ and $Y_2 \sim Wei(k, \lambda)$. Recall that the multivariate density transformation theorem states that $Y$ then has density
\begin{align}
    g(y_1, y_2) = f\left(h_1^{-1}(y_1, y_2), h_2^{-1}(y_1, y_2)\right)\abs{J(y_1, y_2)} \label{gDensity}
\end{align}
Where $f$ is the density of the bivariate normal distribution
\begin{align}
    f(\mathbf{x}) = \frac{1}{2\pi\sqrt{\det(\Sigma)}}\exp\left(-\frac{1}{2}\mathbf{x}^\top \Sigma^{-1}\mathbf{x}\right)
\end{align}
In (\ref{gDensity}) the jacobian $J$ is 
\begin{align}
    J(y_1, y_2) = \det\left(\begin{matrix}
        \frac{\partial h_1^{-1}(y_1, y_2)}{\partial y_1} & \frac{\partial h_1^{-1}(y_1, y_2)}{\partial y_2} \\
        \frac{\partial h_2^{-1}(y_1, y_2)}{\partial y_1} & \frac{\partial h_2^{-1}(y_1, y_2)}{\partial y_2}
    \end{matrix}\right)  
\end{align}
We easily find
\begin{align}
    h_1^{-1}(y_1, y_2) = \frac{y_1-\mu}{\sigma}, \qquad 
    h_2^{-1}(y_1, y_2) = \Phi^{-1}\left(1-e^{-\left(\frac{y_2}{\lambda}\right)^k}\right) 
\end{align}
Differentiating and setting into the definition of the jacobian yields:
\begin{align}
    J(y_1, y_2) = \frac{k\left(\frac{y_2}{\lambda}\right)^ke^{-\left(\frac{y_2}{\lambda}\right)^k}}{\varphi\left(\Phi^{-1}\left(1-e^{-\left(\frac{y_2}{\lambda}\right)^k}\right)\right)y_2\sigma }    
\end{align}
where $\varphi$ is the density of the standard normal distribution. We can then obtain the density by combining above formulae.
\newpage
\section{Source code for various implementations}\label{sourceCodeImplementation}
\subsection{Implementation of bivariate weibull-normal density in C++}\label{densityImplementation}
\begin{lstlisting}[language=C++]
    #include <Rcpp.h>
    // [[Rcpp::export]]
    Rcpp::NumericVector gDensityRcpp(
        Rcpp::NumericVector x, Rcpp::NumericVector y,
        double k, double lambda,
        double mu, double sigma,
        Rcpp::NumericMatrix covariancematrix,
        double eps) {
      int n = x.length();
      Rcpp::NumericMatrix covariancematrixInverse(2, 2);
      covariancematrixInverse(0, 0) = covariancematrix(1, 1);
      covariancematrixInverse(1, 1) = covariancematrix(0, 0);
      covariancematrixInverse(0, 1) = -covariancematrix(0, 1);
      covariancematrixInverse(1, 0) = -covariancematrix(1, 0);
    
      double determinant = covariancematrix(0, 0) * covariancematrix(1, 1) -
        covariancematrix(0, 1) * covariancematrix(1, 0);
      covariancematrixInverse = covariancematrixInverse / determinant;
      Rcpp::NumericVector exponent = Rcpp::pow(x/lambda, k);
      Rcpp::NumericVector exponential = Rcpp::exp(-exponent);
    
      Rcpp::NumericVector updateY = 1-exponential;
      for (int i = 0; i < n; i++) {
        if (updateY[i] == 0) {
          updateY[i] += eps;  // Add eps if the entry is equal to 0
        } else if (updateY[i] == 1) {
          updateY[i] -= eps;  // Subtract eps if the entry is equal to 1
        }
      }
      Rcpp::NumericVector gjacobianVec = k * exponent *
        exponential/(Rcpp::dnorm4(Rcpp::qnorm5(updateY)) * x * sigma + eps);
      Rcpp::NumericVector g1Inverse = (y-mu)/sigma;
      Rcpp::NumericVector g2Inverse = Rcpp::qnorm5(updateY);
    
    
      Rcpp::NumericVector quadraticForm = covariancematrixInverse(0,0)*g2Inverse*g2Inverse + 
        covariancematrixInverse(1,1)*g1Inverse*g1Inverse+
        2*covariancematrixInverse(1,0)*g2Inverse*g1Inverse;
      Rcpp::NumericVector density(n);
      
      density = 1.0/(2*3.141592653589793115997963468544185161590576171875*sqrt(determinant))*
        gjacobianVec*Rcpp::exp(-1.0/2.0*quadraticForm);
      return density;
    }
\end{lstlisting}
\newpage
\subsection{Implementation of the numerical likelihood in C++}
\begin{lstlisting}[language=C++]
    // [[Rcpp::export]]
    double negative_log_likelihood_bivariate_weibull_normal_Rcpp(
        Rcpp::NumericVector step1, Rcpp::NumericVector step2,
        Rcpp::NumericVector mu, Rcpp::NumericVector sigma,
        Rcpp::NumericVector shape, Rcpp::NumericVector scale,
        Rcpp::NumericMatrix Gamma,Rcpp::NumericMatrix covarianceMatrix,
        Rcpp::NumericVector delta, double  eps = 0.001){
      int T = step1.length();
      int N = delta.length();
      Rcpp::NumericMatrix all_probs(T,N);
      for (int i = 0; i < N; i++) {
          all_probs(Rcpp::_ , i) = gDensityRcpp(step1, step2, shape[i], scale[i],
                    mu[i], sigma[i], covarianceMatrix, eps);
      }
      
      Rcpp::NumericVector v(N);
      double llk = 0.0;
      
      // Initialization
      for (int i = 0; i < N; i++) {
        v[i] = delta[i] * all_probs(0, i);
      }
      
      // Loop over time steps
      for (int t = 1; t < T; t++) {
        // Matrix-vector multiplication
        for (int i = 0; i < N; i++) {
          double sumValue = 0.0;
          for (int j = 0; j < N; j++) {
            sumValue += v[j] * Gamma(j, i);
          }
          v[i] = sumValue * all_probs(t, i);
        }
        
        // Log-sum scaling
        double sumV = sum(v);
        llk += log(sumV);
        v = v / sumV;
      }
      return -llk;
    }    
\end{lstlisting}
\newpage
\subsection{Implementation of HMM fit in R}
\begin{lstlisting}[language = R]
fit_weibull_normal_hmmFullRcpp <- function(step1, step2, par, Gamma, delta, covarianceMatrix = NULL, eps = 0.001) { 
    objective_function <- function(par){
    mu <- par[1:3]
    sigma <- par[4:6]
    shape <- par[7:9] 
    scale <- par[10:12]
    Gamma <- diag(3) 
    Gamma[!Gamma] <- par[13:18]
    Gamma <- Gamma / rowSums(Gamma)
    delta <- c(par[19], par[20], 1)
    delta <- delta / sum(delta)
    lik <- negative_log_likelihood_bivariate_weibull_normal_Rcpp(step1, step2, mu, sigma, shape, scale, Gamma, covarianceMatrix, delta, eps)
    return(lik)
    }
        
    wGamma0 <- Gamma[!diag(3)]
    wDelta0 <- delta[-3] / delta[3]
    par0 <- c(par, wGamma0, wDelta0)
    
    mod <- optim(par0, fn = objective_function, method = "L-BFGS-B",
    lower = c(rep(-Inf, 3), rep(0, 3), rep(0, 6), rep(0, 8)),
    upper = c(rep(Inf, 3), rep(Inf, 3), rep(Inf, 6), rep(1, 8)),
    control = list(maxit = 500))
    
    mu_out <- mod$par[1:3]
    sd_out <- mod$par[4:6] 
    shape_out = mod$par[7:9]
    scale_out = mod$par[10:12]
    Gamma_MLE <- diag(3)
    Gamma_MLE[!Gamma_MLE] <- mod$par[13:18] 
    Gamma_MLE <- Gamma_MLE / apply(Gamma_MLE, 1, sum)
    delta_MLE <- c(mod$par[19], mod$par[20], 1)
    delta_MLE <- delta_MLE / sum(delta_MLE)
        
    return(list(mean_normal = mu_out, sd_normal = sd_out, shape_weibull = shape_out,scale_weibull = scale_out, Gamma = Gamma_MLE, delta = delta_MLE, numIter = mod$counts, minimum = mod$value,
            convergence = mod$convergence))
}
\end{lstlisting}
\newpage
\section{Benchmark the markov chain sampler}\label{benchmarkSection}
In the section we show the results of a small benchmark using \cite{microbenchmark}. The implementations were run with the following hardware and software.
\begin{table}[ht]
    \centering
    \begin{tabular}{ll}
      \hline
      \textbf{Specification} & \textbf{Description} \\
      \hline
      Processor (CPU) & Intel i7-4800MQ (8) @ 3.700GHz \\
      RAM & 16 GB \\
      Operating System & Linux Mint 21.1 x86\_64 \\
      Storage & 500 GB SSD \\
      Graphics Card (GPU) & Intel 4th Gen Core Processor \\
      Compiler and Software & R 4.3.0 with C++ compiler g++ 11.3.0\\
      \hline
    \end{tabular}
  \end{table}
\subsection*{The Markov chain sampler}
We compare the two markov chain samplers
\begin{figure}[h!]
    \centering
    \includegraphics[scale = .15]{figures/markovChainSamplers.jpeg}
    \caption{The basic R markov chain sampler compared to more sophisticated C++ implementation}
    \label{markovChainRvRcpp}
\end{figure}